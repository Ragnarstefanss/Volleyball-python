{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import codecs, json\n",
    "import unicodedata\n",
    "# pip install Unidecode  <OR> conda install Unidecode\n",
    "import unidecode\n",
    "import collections\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Variables and what they mean\n",
    "#   duplicate_dict = all duplicates\n",
    "#   dict_removed_single_entries = all duplicates but removed single entries\n",
    "#   duplicate_ids_kept = array of all ids from dict_removed_single_entries\n",
    "#   dict_duplicate_compare_team_members = map values from teams to einstaklingsid\n",
    "#   dict_name_entries = map values from member down one step (name->birthday->values) now (name+birthday->values)\n",
    "#   dict_einstaklingar_teammember_info = map teammember values to correct key in einstaklingsid\n",
    "#   not_the_same_person = when two players are playing in different teams at the same time then they clearly are not the same person"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all csv files\n",
    "domarar = pd.read_csv('csv/blak-domarar.csv', sep=';', header=0)\n",
    "einstaklingar = pd.read_csv('csv/blak-einstaklingar.csv', sep=';', header=0)\n",
    "forsvarsmenn = pd.read_csv('csv/blak-forsvarsmenn.csv', sep=';', header=0)\n",
    "lid = pd.read_csv('csv/blak-lid.csv', sep=';', header=0)\n",
    "lidimoti = pd.read_csv('csv/blak-lidimoti.csv', sep=';', header=0)\n",
    "lidsmenn = pd.read_csv('csv/blak-lidsmenn.csv', sep=';', header=0)\n",
    "lidsstjorar = pd.read_csv('csv/blak-lidsstjorar.csv', sep=';', header=0)\n",
    "thjalfarar = pd.read_csv('csv/blak-thjalfarar.csv', sep=';', header=0)\n",
    "mot = pd.read_csv('csv/blak-mot.csv', sep=';', header=0)\n",
    "\n",
    "# drop all SyndarLids with an ID (SyndarlidID)\n",
    "# (the reason for not dropping using SyndarLid is because I don't trust that column to be inserted correctly with [0,1])\n",
    "lid = lid[lid['SyndarlidID'].isna()]\n",
    "# then dropping those two columns because we don't want virtual teams\n",
    "lid = lid.drop(columns=['SyndarLid', 'SyndarlidID'])\n",
    "\n",
    "# All duplicated birthdays\n",
    "duplicated_einstaklingar = einstaklingar[einstaklingar.duplicated(subset=['Nafn', 'Fdagur', 'Kyn'], keep=False)]\n",
    "duplicated_fdagur_kyn_einstaklingar = einstaklingar[einstaklingar.duplicated(subset=['Fdagur', 'Kyn'], keep=False)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter duplicates by name and birthday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all entries that have duplicated birthdays, then filter that to first_name->birthday-><people entries>\n",
    "duplicate_dict = defaultdict(dict)\n",
    "for index, row in duplicated_fdagur_kyn_einstaklingar.iterrows():\n",
    "    full_name = row['Nafn']\n",
    "    #only get the first part of full name \n",
    "    first_name = full_name.split()[0]\n",
    "    # make first name lowercase\n",
    "    first_name_lowercase = first_name.lower()\n",
    "    # encode icelandic letters to english\n",
    "    first_name_to_english = unidecode.unidecode(first_name_lowercase)\n",
    "    # split birthday into year month and day and ignore second part (sec, min, hour)\n",
    "    Fdagur_date = row['Fdagur'].split()[0]\n",
    "    \n",
    "    if first_name_to_english in duplicate_dict.keys():\n",
    "        if Fdagur_date in duplicate_dict[first_name_to_english].keys():\n",
    "            #if first name and Fdagur (birthday) exist in dict then append to that key (birthday)\n",
    "            duplicate_dict[first_name_to_english][Fdagur_date].append(row.values)\n",
    "        else:\n",
    "            #if first name exists but Fdagur (birthday) does not exist in dict\n",
    "            duplicate_dict[first_name_to_english][Fdagur_date] = [row.values]\n",
    "    else:\n",
    "        #if Fdagur (birthday) does not exist in dict\n",
    "        duplicate_dict[first_name_to_english][Fdagur_date] = [row.values]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove all single birthday entries (since that is not a duplicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all single birthday entries that are not duplicates\n",
    "dict_removed_single_entries = defaultdict(dict)\n",
    "\n",
    "for key, values in duplicate_dict.items():\n",
    "    # key = nafn ('ludvik')\n",
    "    for birthday, arrays in dict(values).items():\n",
    "        # only get duplicates that there exists 2 or more entries for a birthday\n",
    "        if(len(arrays) > 1):\n",
    "            # used for when joining teams table\n",
    "            if key in dict_removed_single_entries.keys():\n",
    "                if birthday in dict_removed_single_entries[key].keys():\n",
    "                    dict_removed_single_entries[key][birthday].append(arrays)\n",
    "                else:\n",
    "                    #if first name exists but Fdagur (birthday) does not exist in dict\n",
    "                    dict_removed_single_entries[key][birthday] = arrays\n",
    "            else:\n",
    "                dict_removed_single_entries[key][birthday] = arrays\n",
    "\n",
    "#dict_removed_single_entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get all ids that exists in duplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all ids in dict_removed_single_entries\n",
    "duplicate_ids_kept = []\n",
    "for key, values in dict_removed_single_entries.items():\n",
    "    # key = nafn ('ludvik')\n",
    "    for birthday, arrays in dict(values).items():\n",
    "        for item in arrays:\n",
    "            duplicate_ids_kept.append(item[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map teams table values to einstaklingsID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if two names are the same person\n",
    "dict_duplicate_compare_team_members = defaultdict(dict)\n",
    "for index, row in lidsmenn.iterrows():\n",
    "    ids = row[\"EinstID\"]\n",
    "    if ids in duplicate_ids_kept:\n",
    "        # now we only view ids that exist for duplicated people\n",
    "        #print(ids)\n",
    "        if ids in dict_duplicate_compare_team_members.keys():\n",
    "            dict_duplicate_compare_team_members[ids].append(row.values)\n",
    "        else:\n",
    "            dict_duplicate_compare_team_members[ids] = [row.values]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map one step down (name->birthday -> value) now (name+birthday -> value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_name_entries = {}\n",
    "for key, value in dict_removed_single_entries.items():\n",
    "    #get key and arrays for each person\n",
    "    for birthday, arrays in dict(value).items():\n",
    "        #get each array for person\n",
    "        #print(\"KEY: \" + key + \" BIRTHDAY: \" + birthday)\n",
    "        new_key = key +\"-\"+ birthday\n",
    "        for item in arrays:\n",
    "            if new_key in dict_name_entries.keys():\n",
    "                dict_name_entries[new_key].append(item[0])\n",
    "            else:\n",
    "                dict_name_entries[new_key] = [item[0]]\n",
    "#dict_name_entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EinstaklingsID+birthday connected to all his data from teams table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_einstaklingar_teammember_info = {}\n",
    "for key, value in dict_name_entries.items():\n",
    "    #print(\"<key>\" + str(key) + \" <value> \" + str(value))\n",
    "    for item in value:\n",
    "        #print(item)\n",
    "        if item in dict_duplicate_compare_team_members.keys():\n",
    "            #print(\"<key>\" + str(key) + \" <item> \" + str(item))\n",
    "            for compare_arrays in dict_duplicate_compare_team_members[item]:\n",
    "                mot_id = compare_arrays[0]\n",
    "                lid_id = compare_arrays[1]\n",
    "                player_id = compare_arrays[2]\n",
    "                date = compare_arrays[3]\n",
    "                date_played = compare_arrays[3].split()[0]\n",
    "                \n",
    "                temp = (str(date) + \" \" + str(mot_id) + \" \" + str(lid_id) + \" \" + str(player_id))   \n",
    "                if key in dict_einstaklingar_teammember_info.keys():\n",
    "                    dict_einstaklingar_teammember_info[key].append(temp)\n",
    "                else:\n",
    "                    dict_einstaklingar_teammember_info[key] = [temp]\n",
    "        #print(\"xxxxxxxxxxxx\")\n",
    "#dict_einstaklingar_teammember_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find if a potential duplicated person played two games at the same time in different teams (then he is not a duplication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_the_same_person = {}\n",
    "\n",
    "def find_duplicates(key, nums):\n",
    "    num_set = set()\n",
    "    duplicates = set()\n",
    "    no_duplicate = -1\n",
    "    sorted_nums = sorted(nums)\n",
    "    \n",
    "    for i in range(len(sorted_nums)):\n",
    "        for j in range(i+1, len(sorted_nums)):\n",
    "            \n",
    "            # team one split\n",
    "            #(str(date) + \" \" + str(mot_id) + \" \" + str(lid_id) +  str(player_id))   \n",
    "            \n",
    "            sort_1 = sorted_nums[i].split()\n",
    "            date_1 = sort_1[0]\n",
    "            mot_id_1 = sort_1[2]\n",
    "            team_id_1 = sort_1[3]\n",
    "            einstaklings_id_1 = sort_1[4]\n",
    "            date_time_str_1 = sort_1[0]+\" \"+sort_1[1]\n",
    "            date_time_obj_1 = datetime.datetime.strptime(date_time_str_1, '%Y-%m-%d %H:%M:%S.%f')\n",
    "            \n",
    "            # team two split\n",
    "            sort_2 = sorted_nums[j].split()\n",
    "            date_2 = sort_2[0]\n",
    "            mot_id_1 = sort_2[2]\n",
    "            team_id_2 = sort_2[3]\n",
    "            einstaklings_id_2 = sort_2[4]    \n",
    "            date_time_str_2 = sort_2[0]+\" \"+sort_2[1]\n",
    "            date_time_obj_2 = datetime.datetime.strptime(date_time_str_2, '%Y-%m-%d %H:%M:%S.%f')\n",
    "            \n",
    "            # time difference between these two entries\n",
    "            time_diff = (date_time_obj_2 - date_time_obj_1).total_seconds()/60\n",
    "            \n",
    "            match_length = 60\n",
    "            if((date_1 == date_2) and (team_id_1 != team_id_2) and (time_diff < match_length)):\n",
    "                # There exist two record for erla with the same einstaklingsid but different teams (6286 and 6285)\n",
    "                # played 6.5 minutes apart\n",
    "                # TODO: figure out how to handle that\n",
    "                if((einstaklings_id_1 != einstaklings_id_2)):\n",
    "                    #print(\"=======================\")\n",
    "                    #print(\"SAME ID\")\n",
    "                    #print(\"Time diff: \" + str(time_diff))\n",
    "                    #print(\"Key: \" + key)\n",
    "                    #print(\"Row 1: \" + sorted_nums[i])\n",
    "                    #print(\"Row 2: \" + sorted_nums[j])\n",
    "                    combined = [sorted_nums[i], sorted_nums[j]]\n",
    "                    \n",
    "                    if key in not_the_same_person.keys():\n",
    "                        not_the_same_person[key].append(combined)\n",
    "                    else:\n",
    "                        not_the_same_person[key] = [combined]\n",
    "\n",
    "for key, value in dict_einstaklingar_teammember_info.items():\n",
    "    #print(value)\n",
    "    find_duplicates(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anna-1972-05-30': [['2005-03-29 13:56:01.373 77 2226 1766',\n",
       "   '2005-03-29 14:03:03.560 68 2227 1768']],\n",
       " 'bragi-1931-04-26': [['2007-01-05 11:01:51.687 102 132 1852',\n",
       "   '2007-01-05 11:09:30.640 102 2873 541']],\n",
       " 'fridrik-1950-12-23': [['2000-04-29 20:50:37.857 1 60 209',\n",
       "   '2000-04-29 21:00:46.300 1 61 507'],\n",
       "  ['2002-04-08 22:06:25.513 15 61 507', '2002-04-08 22:19:56.107 15 60 209']],\n",
       " 'gaetan-1982-03-16': [['2013-10-24 23:15:55.993 232 1830 4268',\n",
       "   '2013-10-24 23:16:41.120 232 3040 4276']],\n",
       " 'heidi-1968-08-09': [['2014-08-13 10:45:27.647 250 4173 2044',\n",
       "   '2014-08-13 11:18:05.767 250 6011 2192']],\n",
       " 'hulda-1962-02-24': [['2005-03-30 17:18:35.810 68 2227 1772',\n",
       "   '2005-03-30 17:20:32.980 77 2226 1773']],\n",
       " 'jounes-1977-03-21': [['2003-10-09 14:08:51.403 46 1019 1231',\n",
       "   '2003-10-09 14:15:56.310 46 1023 1049']],\n",
       " 'kristrun-1969-09-29': [['2008-04-07 15:31:32.937 125 2071 1678',\n",
       "   '2008-04-07 15:50:23.060 121 3261 1830']],\n",
       " 'magnus-1950-02-23': [['2000-04-29 20:54:50.007 1 60 419',\n",
       "   '2000-04-29 21:08:30.990 1 61 489'],\n",
       "  ['2002-04-08 22:05:20.090 15 61 489', '2002-04-08 22:24:49.840 15 60 419']],\n",
       " 'olafur-1959-05-06': [['2005-04-18 22:40:16.903 68 1689 1497',\n",
       "   '2005-04-18 22:51:24.403 68 38 722'],\n",
       "  ['2008-04-24 09:15:58.937 121 2980 722',\n",
       "   '2008-04-24 09:27:52.903 121 38 1497'],\n",
       "  ['2010-05-05 20:55:47.937 165 2980 1497',\n",
       "   '2010-05-05 21:00:41.653 165 1689 722']],\n",
       " 'skjoldur-1947-03-09': [['2001-12-11 19:03:20.107 6 72 178',\n",
       "   '2001-12-11 19:14:21.047 7 27 750']],\n",
       " 'valgeir-1967-10-31': [['2002-05-09 14:41:40.857 15 671 1205',\n",
       "   '2002-05-09 14:48:47.640 15 670 1215']]}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_the_same_person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=====================================================================================\n",
    "="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reverted_back_to_dict = dict(duplicate_dict)\n",
    "#reverted_back_to_dict\n",
    "#file_path = \"json/einstaklingar_map.txt\" ## your path variable\n",
    "#duplicate_dict_json = json.dump(duplicate_dict, codecs.open(file_path, 'w', encoding='utf-8'), separators=(';', ':'), sort_keys=True, indent=4) ### this saves the array in .json format\n",
    "#json_obj = json.dumps(duplicate_dict, indent = 4)\n",
    "#dumped = json.dumps(duplicate_dict, cls=NumpyEncoder)\n",
    "#dumped\n",
    "#pd.DataFrame(reverted_back_to_dict).to_csv(file_path, encoding='utf-8-sig')\n",
    "#duplicate_dict_json = json.dump(reverted_back_to_dict, codecs.open(file_path, 'w', encoding='utf-8-sig'))\n",
    "\n",
    "#json = json.dumps(reverted_back_to_dict)\n",
    "#f = open(file_path,\"w\")\n",
    "#f.write(str(reverted_back_to_dict))\n",
    "#f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=====================================================================================\n",
    "="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FINAL STEP (run after everything is done):\n",
    "\n",
    "#duplicated people put into it's own csv to be browsed later\n",
    "pd.DataFrame(duplicated_einstaklingar).to_csv(\"csv/new/duplicated-einstaklingar.csv\", encoding='utf-8-sig')\n",
    "pd.DataFrame(duplicate_dict).to_csv(\"json/duplicate-map.json\", encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "#save as new csv inside csv/new\n",
    "pd.DataFrame(domarar).to_csv(\"csv/new/blak-domarar.csv\", encoding='utf-8-sig')\n",
    "pd.DataFrame(einstaklingar).to_csv(\"csv/new/blak-einstaklingar.csv\", encoding='utf-8-sig')\n",
    "pd.DataFrame(forsvarsmenn).to_csv(\"csv/new/blak-forsvarsmenn.csv.csv\", encoding='utf-8-sig')\n",
    "pd.DataFrame(lid).to_csv(\"csv/new/blak-lid.csv\", encoding='utf-8-sig')\n",
    "pd.DataFrame(lidimoti).to_csv(\"csv/new/blak-lidimoti.csv\", encoding='utf-8-sig')\n",
    "pd.DataFrame(lidsmenn).to_csv(\"csv/new/blak-lidsmenn.csv\", encoding='utf-8-sig')\n",
    "pd.DataFrame(lidsstjorar).to_csv(\"csv/new/blak-lidsstjorar.csv\", encoding='utf-8-sig')\n",
    "pd.DataFrame(mot).to_csv(\"csv/new/blak-mot.csv\", encoding='utf-8-sig')\n",
    "pd.DataFrame(thjalfarar).to_csv(\"csv/new/blak-thjalfarar.csv\", encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
