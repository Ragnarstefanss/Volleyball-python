{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import codecs, json\n",
    "import unicodedata\n",
    "# pip install Unidecode  <OR> conda install Unidecode\n",
    "import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all csv files\n",
    "domarar = pd.read_csv('csv/blak-domarar.csv', sep=';', header=0)\n",
    "einstaklingar = pd.read_csv('csv/blak-einstaklingar.csv', sep=';', header=0)\n",
    "forsvarsmenn = pd.read_csv('csv/blak-forsvarsmenn.csv', sep=';', header=0)\n",
    "lid = pd.read_csv('csv/blak-lid.csv', sep=';', header=0)\n",
    "lidimoti = pd.read_csv('csv/blak-lidimoti.csv', sep=';', header=0)\n",
    "lidsmenn = pd.read_csv('csv/blak-lidsmenn.csv', sep=';', header=0)\n",
    "lidsstjorar = pd.read_csv('csv/blak-lidsstjorar.csv', sep=';', header=0)\n",
    "thjalfarar = pd.read_csv('csv/blak-thjalfarar.csv', sep=';', header=0)\n",
    "mot = pd.read_csv('csv/blak-mot.csv', sep=';', header=0)\n",
    "\n",
    "# drop all SyndarLids with an ID (SyndarlidID)\n",
    "# (the reason for not dropping using SyndarLid is because I don't trust that column to be inserted correctly with [0,1])\n",
    "lid = lid[lid['SyndarlidID'].isna()]\n",
    "# then dropping those two columns because we don't want virtual teams\n",
    "lid = lid.drop(columns=['SyndarLid', 'SyndarlidID'])\n",
    "\n",
    "# All duplicated birthdays\n",
    "duplicated_einstaklingar = einstaklingar[einstaklingar.duplicated(subset=['Nafn', 'Fdagur', 'Kyn'], keep=False)]\n",
    "duplicated_fdagur_kyn_einstaklingar = einstaklingar[einstaklingar.duplicated(subset=['Fdagur', 'Kyn'], keep=False)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all entries that have duplicated birthdays, then filter that to first_name->birthday-><people entries>\n",
    "duplicate_dict = defaultdict(dict)\n",
    "for index, row in duplicated_fdagur_kyn_einstaklingar.iterrows():\n",
    "    full_name = row['Nafn']\n",
    "    #only get the first part of full name \n",
    "    first_name = full_name.split()[0]\n",
    "    # make first name lowercase\n",
    "    first_name_lowercase = first_name.lower()\n",
    "    # encode icelandic letters to english\n",
    "    first_name_to_english = unidecode.unidecode(first_name_lowercase)\n",
    "    # split birthday into year month and day and ignore second part (sec, min, hour)\n",
    "    Fdagur_date = row['Fdagur'].split()[0]\n",
    "    \n",
    "    if first_name_to_english in duplicate_dict.keys():\n",
    "        if Fdagur_date in duplicate_dict[first_name_to_english].keys():\n",
    "            #if first name and Fdagur (birthday) exist in dict then append to that key (birthday)\n",
    "            duplicate_dict[first_name_to_english][Fdagur_date].append(row.values)\n",
    "        else:\n",
    "            #if first name exists but Fdagur (birthday) does not exist in dict\n",
    "            duplicate_dict[first_name_to_english][Fdagur_date] = [row.values]\n",
    "    else:\n",
    "        #if Fdagur (birthday) does not exist in dict\n",
    "        duplicate_dict[first_name_to_english][Fdagur_date] = [row.values]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all single birthday entries that are not duplicates\n",
    "dict_removed_single_entries = defaultdict(dict)\n",
    "for key, values in duplicate_dict.items():\n",
    "    # key = nafn ('ludvik')\n",
    "    for birthday, arrays in dict(values).items():\n",
    "        # only get duplicates that there exists 2 or more entries for birthday\n",
    "        if(len(arrays) > 1):\n",
    "            tmp2 = {birthday: arrays}\n",
    "            \n",
    "            if key in dict_removed_single_entries.keys():\n",
    "                if birthday in dict_removed_single_entries[key].keys():\n",
    "                    dict_removed_single_entries[key][birthday].append(arrays)\n",
    "                else:\n",
    "                    #if first name exists but Fdagur (birthday) does not exist in dict\n",
    "                    dict_removed_single_entries[key][birthday] = arrays\n",
    "            else:\n",
    "                dict_removed_single_entries[key][birthday] = arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1996-06-22': [array([2949, 'aldís anna höskuldsdóttir', '1996-06-22 00:00:00.000',\n",
       "         'kvk', 'K.A.', 'aldis_anna@hotmail.com', nan, nan, nan, '8681980',\n",
       "         '4611143', nan, '2010-02-25 13:52:40.360', 169.0], dtype=object),\n",
       "  array([2950, 'aldís anna höskuldsdóttir', '1996-06-22 00:00:00.000',\n",
       "         'kvk', 'K.A.', 'aldis_anna@hotmail.com', nan, nan, nan, '8681980',\n",
       "         '4611143', nan, '2010-02-25 13:52:42.780', 169.0], dtype=object)]}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_removed_single_entries['aldis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1996-06-22': [array([2949, 'aldís anna höskuldsdóttir', '1996-06-22 00:00:00.000',\n",
       "         'kvk', 'K.A.', 'aldis_anna@hotmail.com', nan, nan, nan, '8681980',\n",
       "         '4611143', nan, '2010-02-25 13:52:40.360', 169.0], dtype=object),\n",
       "  array([2950, 'aldís anna höskuldsdóttir', '1996-06-22 00:00:00.000',\n",
       "         'kvk', 'K.A.', 'aldis_anna@hotmail.com', nan, nan, nan, '8681980',\n",
       "         '4611143', nan, '2010-02-25 13:52:42.780', 169.0], dtype=object)],\n",
       " '1990-06-19': [array([3870, 'Aldís Garðarsdóttir', '1990-06-19 00:00:00.000', 'kvk', nan,\n",
       "         'aldisgardars@gmail.com', nan, nan, nan, nan, nan, nan,\n",
       "         '2012-10-17 19:06:57.533', 0.0], dtype=object)]}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_dict['aldis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if two names are the same person\n",
    "dict_duplicate_compare_team_members = defaultdict(dict)\n",
    "for index, row in lidsmenn.iterrows():\n",
    "    ids = row[\"EinstID\"]\n",
    "    \n",
    "    if ids in duplicated_fdagur_kyn_einstaklingar[\"EinstID\"]:\n",
    "        # now we only view ids that exist for duplicated people\n",
    "        if ids in dict_duplicate_compare_team_members.keys():\n",
    "            dict_duplicate_compare_team_members[ids].append(row.values)\n",
    "        else:\n",
    "            dict_duplicate_compare_team_members[ids] = [row.values]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict_duplicate_compare_team_members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-50-8aa0c16fa644>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-50-8aa0c16fa644>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    #print(\"--------------\")\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for key, value in dict_removed_single_entries.items():\n",
    "    #get key and arrays for each person\n",
    "    for dict_key, dict_value in dict(value).items():\n",
    "        #get each array for person\n",
    "        #print(\"KEY: \" + key + \" BIRTHDAY: \" + dict_key)\n",
    "        for a in dict_value:\n",
    "            #print(a)\n",
    "        #print(\"--------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict(duplicated_fdagur_kyn_einstaklingar)\n",
    "\n",
    "# all duplicates\n",
    "#duplicate_dict\n",
    "\n",
    "# all duplicates for lúðvík\n",
    "#duplicate_dict[\"ludvik\"]\n",
    "\n",
    "#duplicate_dict[\"ludvik\"]['1969-03-31'][0]\n",
    "#duplicate_dict[\"ludvik\"]['1969-03-31'][1]\n",
    "\n",
    "#duplicate_dict\n",
    "#dict_removed_single_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverted_back_to_dict = dict(duplicate_dict)\n",
    "#reverted_back_to_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"json/einstaklingar_map.txt\" ## your path variable\n",
    "#duplicate_dict_json = json.dump(duplicate_dict, codecs.open(file_path, 'w', encoding='utf-8'), separators=(';', ':'), sort_keys=True, indent=4) ### this saves the array in .json format\n",
    "#json_obj = json.dumps(duplicate_dict, indent = 4)\n",
    "#dumped = json.dumps(duplicate_dict, cls=NumpyEncoder)\n",
    "#dumped\n",
    "#pd.DataFrame(reverted_back_to_dict).to_csv(file_path, encoding='utf-8-sig')\n",
    "#duplicate_dict_json = json.dump(reverted_back_to_dict, codecs.open(file_path, 'w', encoding='utf-8-sig'))\n",
    "\n",
    "#json = json.dumps(reverted_back_to_dict)\n",
    "#f = open(file_path,\"w\")\n",
    "#f.write(str(reverted_back_to_dict))\n",
    "#f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=====================================================================================\n",
    "="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FINAL STEP (run after everything is done):\n",
    "\n",
    "#duplicated people put into it's own csv to be browsed later\n",
    "pd.DataFrame(duplicated_einstaklingar).to_csv(\"csv/new/duplicated-einstaklingar.csv\", encoding='utf-8-sig')\n",
    "pd.DataFrame(duplicate_dict).to_csv(\"json/duplicate-map.json\", encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "#save as new csv inside csv/new\n",
    "pd.DataFrame(domarar).to_csv(\"csv/new/blak-domarar.csv\", encoding='utf-8-sig')\n",
    "pd.DataFrame(einstaklingar).to_csv(\"csv/new/blak-einstaklingar.csv\", encoding='utf-8-sig')\n",
    "pd.DataFrame(forsvarsmenn).to_csv(\"csv/new/blak-forsvarsmenn.csv.csv\", encoding='utf-8-sig')\n",
    "pd.DataFrame(lid).to_csv(\"csv/new/blak-lid.csv\", encoding='utf-8-sig')\n",
    "pd.DataFrame(lidimoti).to_csv(\"csv/new/blak-lidimoti.csv\", encoding='utf-8-sig')\n",
    "pd.DataFrame(lidsmenn).to_csv(\"csv/new/blak-lidsmenn.csv\", encoding='utf-8-sig')\n",
    "pd.DataFrame(lidsstjorar).to_csv(\"csv/new/blak-lidsstjorar.csv\", encoding='utf-8-sig')\n",
    "pd.DataFrame(mot).to_csv(\"csv/new/blak-mot.csv\", encoding='utf-8-sig')\n",
    "pd.DataFrame(thjalfarar).to_csv(\"csv/new/blak-thjalfarar.csv\", encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
