{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import codecs, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all csv files\n",
    "domarar = pd.read_csv('csv/blak-domarar.csv', sep=';', header=0)\n",
    "einstaklingar = pd.read_csv('csv/blak-einstaklingar.csv', sep=';', header=0)\n",
    "forsvarsmenn = pd.read_csv('csv/blak-forsvarsmenn.csv', sep=';', header=0)\n",
    "lid = pd.read_csv('csv/blak-lid.csv', sep=';', header=0)\n",
    "lidimoti = pd.read_csv('csv/blak-lidimoti.csv', sep=';', header=0)\n",
    "lidsmenn = pd.read_csv('csv/blak-lidsmenn.csv', sep=';', header=0)\n",
    "lidsstjorar = pd.read_csv('csv/blak-lidsstjorar.csv', sep=';', header=0)\n",
    "thjalfarar = pd.read_csv('csv/blak-thjalfarar.csv', sep=';', header=0)\n",
    "mot = pd.read_csv('csv/blak-mot.csv', sep=';', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all SyndarLids with an ID (SyndarlidID)\n",
    "# (the reason for not dropping using SyndarLid is because I don't trust that column to be inserted correctly with [0,1])\n",
    "lid = lid[lid['SyndarlidID'].isna()]\n",
    "# then dropping those two columns because we don't want virtual teams\n",
    "lid = lid.drop(columns=['SyndarLid', 'SyndarlidID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data\n",
    "#print(help(einstaklingar))\n",
    "#print(domarar)\n",
    "#print(einstaklingar)\n",
    "#print(forsvarsmenn)\n",
    "#print(lid.columns)\n",
    "#print(lidimoti)\n",
    "#print(lidsmenn)\n",
    "#print(lidsstjorar)\n",
    "#print(mot)\n",
    "#print(thjalfarar)\n",
    "\n",
    "## describe\n",
    "#print(domarar.describe())\n",
    "#print(einstaklingar.describe())\n",
    "#print(forsvarsmenn.describe())\n",
    "#print(lid.describe())\n",
    "#print(lidimoti.describe())\n",
    "#print(lidsmenn.describe())\n",
    "#print(lidsstjorar.describe())\n",
    "#print(mot.describe())\n",
    "#print(thjalfarar.describe())\n",
    "\n",
    "## dtypes\n",
    "#domarar.dtypes\n",
    "#einstaklingar.dtypes\n",
    "#forsvarsmenn.dtypes\n",
    "#lid.dtypes\n",
    "#lidimoti.dtypes\n",
    "#lidsmenn.dtypes\n",
    "#lidsstjorar.dtypes\n",
    "#mot.dtypes\n",
    "#thjalfarar.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All duplicated birthdays\n",
    "duplicated_einstaklingar = einstaklingar[einstaklingar.duplicated(subset=['Nafn', 'Fdagur', 'Kyn'], keep=False)]\n",
    "duplicated_fdagur_kyn_einstaklingar = einstaklingar[einstaklingar.duplicated(subset=['Fdagur', 'Kyn'], keep=False)]\n",
    "#print(duplicated_fdagur_kyn_einstaklingar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_dict = defaultdict(dict)\n",
    "\n",
    "for index, row in duplicated_fdagur_kyn_einstaklingar.iterrows():\n",
    "    full_name = row['Nafn']\n",
    "    first_name = full_name.split()[0]\n",
    "    first_name_lowercase = first_name.lower()\n",
    "    Fdagur_date = row['Fdagur'].split()[0]\n",
    "    \n",
    "    #dict_by_firstname = duplicate_dict[first_name_lowercase] \n",
    "    if first_name_lowercase in duplicate_dict.keys():\n",
    "        if Fdagur_date in duplicate_dict[first_name_lowercase].keys():\n",
    "            duplicate_dict[first_name_lowercase][Fdagur_date].append(row.values)\n",
    "        else:\n",
    "            duplicate_dict[first_name_lowercase][Fdagur_date] = [row.values]\n",
    "    else:\n",
    "        #if Fdagur does not exist ->\n",
    "        duplicate_dict[first_name_lowercase][Fdagur_date] = [row.values]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1996-09-02': [array([4160, 'Lúðvík', '1996-09-02 00:00:00.000', 'kk ', nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, '2013-04-28 10:50:35.960', 0.0],\n",
       "        dtype=object),\n",
       "  array([4167, 'Lúðvík Már Matthíasson', '1996-09-02 00:00:00.000', 'kk ',\n",
       "         'HK', nan, nan, nan, nan, nan, nan, nan, '2013-09-03 21:00:29.950',\n",
       "         0.0], dtype=object)],\n",
       " '1969-03-31': [array([866, 'Lúðvík Kristinsson', '1969-03-31 00:00:00.000', 'kk ', nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, '2001-04-17 12:12:41.047', nan],\n",
       "        dtype=object),\n",
       "  array([2299, 'Lúðvík Kristinsson', '1969-03-31 00:00:00.000', 'kk ', nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, '2007-04-26 11:38:05.860', nan],\n",
       "        dtype=object)]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dict(duplicated_fdagur_kyn_einstaklingar)\n",
    "\n",
    "# all duplicates\n",
    "#duplicate_dict\n",
    "\n",
    "# all duplicates for lúðvík\n",
    "#duplicate_dict[\"lúðvík\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverted_back_to_dict = dict(duplicate_dict)\n",
    "#reverted_back_to_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    \"\"\" Special json encoder for numpy types \"\"\"\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, (np.ndarray,)):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"json/einstaklingar_map.txt\" ## your path variable\n",
    "#duplicate_dict_json = json.dump(duplicate_dict, codecs.open(file_path, 'w', encoding='utf-8'), separators=(';', ':'), sort_keys=True, indent=4) ### this saves the array in .json format\n",
    "#json_obj = json.dumps(duplicate_dict, indent = 4)\n",
    "#dumped = json.dumps(duplicate_dict, cls=NumpyEncoder)\n",
    "#dumped\n",
    "#pd.DataFrame(reverted_back_to_dict).to_csv(file_path, encoding='utf-8-sig')\n",
    "#duplicate_dict_json = json.dump(reverted_back_to_dict, codecs.open(file_path, 'w', encoding='utf-8-sig'))\n",
    "\n",
    "#json = json.dumps(reverted_back_to_dict)\n",
    "#f = open(file_path,\"w\")\n",
    "#f.write(str(reverted_back_to_dict))\n",
    "#f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FINAL STEP (run after everything is done):\n",
    "\n",
    "#duplicated people put into it's own csv to be browsed later\n",
    "pd.DataFrame(duplicated_einstaklingar).to_csv(\"csv/new/duplicated-einstaklingar.csv\", encoding='utf-8-sig')\n",
    "pd.DataFrame(duplicate_dict).to_csv(\"json/duplicate-map.json\", encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "#save as new csv inside csv/new\n",
    "pd.DataFrame(domarar).to_csv(\"csv/new/blak-domarar.csv\", encoding='utf-8-sig')\n",
    "pd.DataFrame(einstaklingar).to_csv(\"csv/new/blak-einstaklingar.csv\", encoding='utf-8-sig')\n",
    "pd.DataFrame(forsvarsmenn).to_csv(\"csv/new/blak-forsvarsmenn.csv.csv\", encoding='utf-8-sig')\n",
    "pd.DataFrame(lid).to_csv(\"csv/new/blak-lid.csv\", encoding='utf-8-sig')\n",
    "pd.DataFrame(lidimoti).to_csv(\"csv/new/blak-lidimoti.csv\", encoding='utf-8-sig')\n",
    "pd.DataFrame(lidsmenn).to_csv(\"csv/new/blak-lidsmenn.csv\", encoding='utf-8-sig')\n",
    "pd.DataFrame(lidsstjorar).to_csv(\"csv/new/blak-lidsstjorar.csv\", encoding='utf-8-sig')\n",
    "pd.DataFrame(mot).to_csv(\"csv/new/blak-mot.csv\", encoding='utf-8-sig')\n",
    "pd.DataFrame(thjalfarar).to_csv(\"csv/new/blak-thjalfarar.csv\", encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
